{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy \n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.svm import LinearSVR,NuSVR,SVR\n",
    "from sklearn.tree import DecisionTreeRegressor,ExtraTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer, median_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from random import uniform,randint\n",
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_models = ['LinearRegression', 'Ridge', 'SGDRegressor', 'ElasticNet,Lars',\n",
    "        'Lasso', 'LassoLars','OrthogonalMatchingPursuit','ARDRegression','BayesianRidge','HuberRegressor',\n",
    "        'RANSACRegressor', 'TheilSenRegressor', 'PoissonRegressor','TweedieRegressor','GammaRegressor',\n",
    "        'PassiveAggressiveRegressor']\n",
    "models = []\n",
    "for model in linear_models:\n",
    "    try:\n",
    "        exec(f\"from sklearn.linear_model import {model}\")\n",
    "    except ImportError:\n",
    "        print(f\"Error importing {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('finaldata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if(df[col].dtype == 'bool'):\n",
    "        df[col] = pd.factorize(df[col])[0] \n",
    "df = df.reset_index(drop=True)\n",
    "df= df.drop(columns='listingInfo.buyItNowAvailable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_and_test_data(df):\n",
    "    Y_targets = np.array(df['Price'].values)\n",
    "    X = np.array(df.drop(columns='Price').values)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled,Y_targets,test_size=0.2,random_state=42,\n",
    "                                                   shuffle=True)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = create_training_and_test_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [RandomForestRegressor(),GradientBoostingRegressor(),SVR(),NuSVR(),\n",
    "          Ridge(),BayesianRidge(),ARDRegression(),HuberRegressor(),LinearSVR(),\n",
    "         ]\n",
    "\n",
    "max_features = [randint(50,82) for p in range(0, 4)]\n",
    "max_features.append(None)\n",
    "\n",
    "list_of_param_grids = [{\n",
    "    'n_estimators' : numpy.random.randint(10,1000,5).astype(int),\n",
    "    ## normally distributed with mean.0.25, std = 0.1 and range[0,1]\n",
    "    'min_samples_split' : numpy.random.randint(2,10,5).astype(int)\n",
    "    },\n",
    "    {'loss' : ['ls','lad','huber'],\n",
    "    'learning_rate' : numpy.random.uniform(0.001,0.3,5),\n",
    "    'n_estimators' : numpy.random.randint(10,1000,5),\n",
    "    'min_samples_split' : numpy.random.randint(2,10,5),\n",
    "    'max_features' : max_features\n",
    "    },\n",
    "    {'C' : numpy.random.uniform(0.1,10,5),\n",
    "    'kernel' : ['linear','poly','rbf','sigmoid'],\n",
    "    'degree' : numpy.random.randint(1,5,5),\n",
    "    'gamma' : ['scale','auto'],\n",
    "    'epsilon' : numpy.random.uniform(0.1,3,5)\n",
    "    },  \n",
    "    {'C' : numpy.random.uniform(0.1,10,5),\n",
    "    'kernel' : ['linear','poly','rbf','sigmoid'],\n",
    "    'degree' : numpy.random.randint(1,5,5),\n",
    "    'gamma' : ['scale','auto'],\n",
    "    'nu' : numpy.random.uniform(0.1,1,5)\n",
    "    },\n",
    "    {'n_iter' : numpy.random.randint(300,1000,5),\n",
    "    'alpha_1' : numpy.random.uniform(1e-8,1e-4,5),\n",
    "    'alpha_2' : numpy.random.uniform(1e-8,1e-4,5),\n",
    "    'lambda_1' : numpy.random.uniform(1e-8,1e-4,5),\n",
    "    'lambda_2' : numpy.random.uniform(1e-8,1e-4,5),\n",
    "    },\n",
    "    {'alpha' : numpy.random.uniform(1,1000,5)},\n",
    "    {'n_iter' : numpy.random.randint(300,1000,5),\n",
    "    'alpha_1' : numpy.random.uniform(1e-8,1e-4,5),\n",
    "    'alpha_2' : numpy.random.uniform(1e-8,1e-4,5),\n",
    "    'lambda_1' : numpy.random.uniform(1e-8,1e-4,5),\n",
    "    'lambda_2' : numpy.random.uniform(1e-8,1e-4,5),\n",
    "    },\n",
    "    {\n",
    "    'epsilon' : numpy.random.uniform(1.01,2.7,5),\n",
    "    'max_iter' : numpy.random.randint(100,300,5),\n",
    "    'alpha' : numpy.random.uniform(0.00001,0.00,5),\n",
    "    },\n",
    "    {\n",
    "    'C' : numpy.random.uniform(0.1,10,5),\n",
    "    'epsilon' : numpy.random.uniform(0,1,5),\n",
    "    'dual' : [True,False],\n",
    "    },  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_models(models,params,X_train,y_train,X_test,y_test):\n",
    "    y_test_squared = np.square(y_test)\n",
    "    for i in range(len(models)):\n",
    "        df = pd.DataFrame(columns=['Model','CV Score','Test RMSE (Â£)','Test MAPE (%)','Best Params','Time Taken'])\n",
    "        start = time.time()\n",
    "        row_to_add = []\n",
    "        model = models[i]\n",
    "        param = params[i]\n",
    "        filename = f'{model}.pkl'\n",
    "        print(f'Doing Model : {model} : Number {i+1} : Out of {len(models)}')\n",
    "        grid_search_model = model\n",
    "        reg = RandomizedSearchCV(grid_search_model,param,scoring='neg_mean_squared_error',\n",
    "                        cv=10,random_state=42, return_train_score=True,\n",
    "                        verbose=1,n_iter=100)\n",
    "        param_search = reg.fit(X_train,y_train)\n",
    "        best_params = param_search.best_estimator_.get_params()\n",
    "        \n",
    "        best_cv_score = np.sqrt(-param_search.best_score_)\n",
    "        \n",
    "        predictions = param_search.predict(X_test)\n",
    "        predictions_squared = np.square(predictions)\n",
    "        \n",
    "        test_mse = mean_squared_error(y_test_squared,predictions_squared)\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_mape = mean_absolute_percentage_error(y_test_squared, predictions_squared)\n",
    "             \n",
    "        end = time.time()\n",
    "        time_taken = end - start\n",
    "        \n",
    "        row_to_add.extend([model,best_cv_score,test_rmse,test_mape,best_params,time_taken])\n",
    "        series_to_append = pd.Series(row_to_add,index=df.columns)\n",
    "        df = df.append(series_to_append,ignore_index=True)\n",
    "        df.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_models(models,list_of_param_grids,X_train,y_train,X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
