{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.svm import LinearSVR,NuSVR,SVR\n",
    "from sklearn.tree import DecisionTreeRegressor,ExtraTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from random import uniform,randint\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_models = ['LinearRegression', 'Ridge', 'SGDRegressor', 'ElasticNet,Lars',\n",
    "        'Lasso', 'LassoLars','OrthogonalMatchingPursuit','ARDRegression','BayesianRidge','HuberRegressor',\n",
    "        'RANSACRegressor', 'TheilSenRegressor', 'PoissonRegressor','TweedieRegressor','GammaRegressor',\n",
    "        'PassiveAggressiveRegressor']\n",
    "models = []\n",
    "for model in linear_models:\n",
    "    try:\n",
    "        exec(f\"from sklearn.linear_model import {model}\")\n",
    "    except ImportError:\n",
    "        print(f\"Error importing {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('finaldata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>globalId</th>\n",
       "      <th>primaryCategory.categoryName</th>\n",
       "      <th>paymentMethod</th>\n",
       "      <th>autoPay</th>\n",
       "      <th>sellerInfo.feedbackScore</th>\n",
       "      <th>sellerInfo.positiveFeedbackPercent</th>\n",
       "      <th>sellerInfo.feedbackRatingStar</th>\n",
       "      <th>sellerInfo.topRatedSeller</th>\n",
       "      <th>shippingInfo.shippingServiceCost.value</th>\n",
       "      <th>shippingInfo.shippingType</th>\n",
       "      <th>...</th>\n",
       "      <th>fault in desc</th>\n",
       "      <th>below in desc</th>\n",
       "      <th>new in desc</th>\n",
       "      <th>spares in desc</th>\n",
       "      <th>Day Started</th>\n",
       "      <th>Day Ended</th>\n",
       "      <th>Time Started</th>\n",
       "      <th>Time Ended</th>\n",
       "      <th>Start Price</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296.373739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.887521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.358858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986582</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   globalId  primaryCategory.categoryName  paymentMethod  autoPay  \\\n",
       "0         0                             0              0    False   \n",
       "1         0                             0              0    False   \n",
       "2         0                             0              0    False   \n",
       "3         0                             0              0    False   \n",
       "4         0                             0              0    False   \n",
       "\n",
       "   sellerInfo.feedbackScore  sellerInfo.positiveFeedbackPercent  \\\n",
       "0                         2                                   1   \n",
       "1                         3                                   1   \n",
       "2                         1                                   1   \n",
       "3                         2                                   1   \n",
       "4                         3                                   2   \n",
       "\n",
       "   sellerInfo.feedbackRatingStar  sellerInfo.topRatedSeller  \\\n",
       "0                              0                      False   \n",
       "1                              1                      False   \n",
       "2                              2                      False   \n",
       "3                              0                      False   \n",
       "4                              1                      False   \n",
       "\n",
       "   shippingInfo.shippingServiceCost.value  shippingInfo.shippingType  ...  \\\n",
       "0                                    0.00                          0  ...   \n",
       "1                                    4.99                          1  ...   \n",
       "2                                    9.50                          1  ...   \n",
       "3                                    7.50                          1  ...   \n",
       "4                                    0.00                          0  ...   \n",
       "\n",
       "   fault in desc  below in desc  new in desc  spares in desc  Day Started  \\\n",
       "0              0              0            0               0            0   \n",
       "1              1              0            0               0            1   \n",
       "2              0              0            0               0            0   \n",
       "3              0              0            1               0            1   \n",
       "4              0              0            1               0            2   \n",
       "\n",
       "   Day Ended  Time Started  Time Ended  Start Price  Country  \n",
       "0          0             0           0   296.373739        0  \n",
       "1          0             0           1    68.887521        0  \n",
       "2          1             1           0    90.358858        1  \n",
       "3          2             1           0     0.000000        0  \n",
       "4          1             1           0     0.986582        0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if(df[col].dtype == 'bool'):\n",
    "        df[col] = pd.factorize(df[col])[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_and_test_data(df):\n",
    "    Y_targets = np.array(df['Price'].values)\n",
    "    X = np.array(df.drop(columns='Price').values)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled,Y_targets,test_size=0.2,random_state=42,\n",
    "                                                   shuffle=True)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = create_training_and_test_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14394, 82)\n",
      "(3599, 82)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(),Ridge(),SGDRegressor(),ElasticNet(),Lars(),Lasso(),\n",
    "          LassoLars(),OrthogonalMatchingPursuit(),ARDRegression(),BayesianRidge(),\n",
    "          HuberRegressor(),PoissonRegressor(),TweedieRegressor(),GammaRegressor(),\n",
    "          PassiveAggressiveRegressor(),RANSACRegressor(),LinearSVR(),NuSVR(),\n",
    "          SVR(),DecisionTreeRegressor(),ExtraTreeRegressor(),TheilSenRegressor(),\n",
    "         RandomForestRegressor(), AdaBoostRegressor(), GradientBoostingRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(models,X_train,y_train,X_test,y_test):\n",
    "    y_test_squared = np.square(y_test)\n",
    "    y_train_squared = np.square(y_train)\n",
    "    x_train_squared = np.square(X_train)\n",
    "    x_test_squared = np.square(X_test)\n",
    "    \n",
    "    total_time_start = time.time()\n",
    "    model_evaluation = pd.DataFrame(columns=['Model','Train MAPE','Train RMSE','Train CV Mean','Train CV STD',\n",
    "                                            'Test MAPE','Test RMSE','Time Taken'])\n",
    "    for index,model in enumerate(models):\n",
    "        print(f'Now doing : {model} : This is model : {index + 1} out of {len(models)} ')\n",
    "        df_values = []\n",
    "        start = time.time()\n",
    "        current_model = model.fit(X_train,y_train)\n",
    "        model_train_predictions = current_model.predict(X_train)\n",
    "        model_train_predictions_squared = np.square(model_train_predictions)\n",
    "        train_mse = mean_squared_error(y_train_squared,model_train_predictions_squared)\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        model_train_cv_score = cross_val_score(current_model, X_train, y_train,\n",
    "                        scoring='neg_mean_squared_error',cv=10)\n",
    "        \n",
    "        model_train_scores_mean = model_train_cv_score.mean()\n",
    "        train_scores_rmse = np.sqrt(-model_train_scores_mean)\n",
    "        model_train_scores_std = model_train_cv_score.std()\n",
    "        model_train_mape = mean_absolute_percentage_error(y_train_squared, model_train_predictions_squared)\n",
    "        \n",
    "        model_test_predictions = current_model.predict(X_test)\n",
    "        model_test_predictions_squared = np.square(model_test_predictions)\n",
    "        model_test_mse = mean_squared_error(y_test_squared, model_test_predictions_squared)\n",
    "        test_rmse = np.sqrt(model_test_mse)\n",
    "        model_test_mape = mean_absolute_percentage_error(y_test_squared, model_test_predictions_squared)\n",
    "        end = time.time()\n",
    "        time_taken = end - start\n",
    "        df_values.extend([model,model_train_mape,train_rmse,train_scores_rmse,\n",
    "                          model_train_scores_std,model_test_mape,test_rmse,time_taken])\n",
    "        series_to_append = pd.Series(df_values,index=model_evaluation.columns)\n",
    "        model_evaluation = model_evaluation.append(series_to_append,ignore_index=True)\n",
    "    total_time_end = time.time()\n",
    "    print(f'Time taken : {total_time_end - total_time_start}')\n",
    "    return model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing : LinearRegression() : This is model : 1 out of 25 \n",
      "Now doing : Ridge() : This is model : 2 out of 25 \n",
      "Now doing : SGDRegressor() : This is model : 3 out of 25 \n",
      "Now doing : ElasticNet() : This is model : 4 out of 25 \n",
      "Now doing : Lars() : This is model : 5 out of 25 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.313e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=6.540e-04, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=3.875e-04, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.131e-04, with an active set of 62 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=6.389e-05, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.854e-05, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.988e-05, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.011e-06, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=5.661e-04, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=3.970e-04, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.014e-04, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=5.351e-05, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.217e-05, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=4.143e-06, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.339e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=6.511e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=3.375e-04, with an active set of 44 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.476e-04, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.399e-05, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.421e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=7.732e-04, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.815e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.089e-04, with an active set of 66 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.863e-06, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.409e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=7.348e-04, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=3.668e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.075e-04, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=1.462e-05, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=5.537e-06, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.386e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.956e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.276e-04, with an active set of 50 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.235e-05, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.068e-05, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=3.122e-06, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.446e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=7.296e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.380e-04, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.366e-04, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.160e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.601e-05, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.777e-05, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.327e-05, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=4.367e-06, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=2.037e-06, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.351e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=6.613e-04, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=4.158e-04, with an active set of 39 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=1.211e-04, with an active set of 63 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=8.971e-06, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.546e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.067e-04, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.338e-04, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=4.473e-05, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=2.305e-05, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=7.602e-06, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=1.248e-06, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing : Lasso() : This is model : 6 out of 25 \n",
      "Now doing : LassoLars() : This is model : 7 out of 25 \n",
      "Now doing : OrthogonalMatchingPursuit() : This is model : 8 out of 25 \n",
      "Now doing : ARDRegression() : This is model : 9 out of 25 \n",
      "Now doing : BayesianRidge() : This is model : 10 out of 25 \n",
      "Now doing : HuberRegressor() : This is model : 11 out of 25 \n",
      "Now doing : PoissonRegressor() : This is model : 12 out of 25 \n",
      "Now doing : TweedieRegressor() : This is model : 13 out of 25 \n",
      "Now doing : GammaRegressor() : This is model : 14 out of 25 \n",
      "Now doing : PassiveAggressiveRegressor() : This is model : 15 out of 25 \n",
      "Now doing : RANSACRegressor() : This is model : 16 out of 25 \n",
      "Now doing : LinearSVR() : This is model : 17 out of 25 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing : NuSVR() : This is model : 18 out of 25 \n",
      "Now doing : SVR() : This is model : 19 out of 25 \n",
      "Now doing : DecisionTreeRegressor() : This is model : 20 out of 25 \n",
      "Now doing : ExtraTreeRegressor() : This is model : 21 out of 25 \n",
      "Now doing : TheilSenRegressor(max_subpopulation=10000) : This is model : 22 out of 25 \n",
      "Now doing : RandomForestRegressor() : This is model : 23 out of 25 \n",
      "Now doing : AdaBoostRegressor() : This is model : 24 out of 25 \n",
      "Now doing : GradientBoostingRegressor() : This is model : 25 out of 25 \n",
      "Time taken : 1148.3054769039154\n"
     ]
    }
   ],
   "source": [
    "df_models = run_models(models,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Train CV Mean</th>\n",
       "      <th>Train CV STD</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>25.61</td>\n",
       "      <td>32.64</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1552236677610843430243532800.00</td>\n",
       "      <td>13148722540706265264736436224.00</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge()</td>\n",
       "      <td>25.59</td>\n",
       "      <td>32.65</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>25.86</td>\n",
       "      <td>30.43</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDRegressor()</td>\n",
       "      <td>25.63</td>\n",
       "      <td>33.44</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.69</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>41.46</td>\n",
       "      <td>45.44</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>43.95</td>\n",
       "      <td>44.97</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lars()</td>\n",
       "      <td>25.78</td>\n",
       "      <td>32.62</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.13</td>\n",
       "      <td>26.09</td>\n",
       "      <td>30.44</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso()</td>\n",
       "      <td>46.31</td>\n",
       "      <td>50.42</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>49.03</td>\n",
       "      <td>49.88</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoLars()</td>\n",
       "      <td>50.96</td>\n",
       "      <td>53.97</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.24</td>\n",
       "      <td>54.35</td>\n",
       "      <td>53.59</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OrthogonalMatchingPursuit()</td>\n",
       "      <td>30.14</td>\n",
       "      <td>36.05</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.17</td>\n",
       "      <td>30.95</td>\n",
       "      <td>34.74</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARDRegression()</td>\n",
       "      <td>25.62</td>\n",
       "      <td>32.69</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>25.90</td>\n",
       "      <td>30.44</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BayesianRidge()</td>\n",
       "      <td>25.62</td>\n",
       "      <td>32.63</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.13</td>\n",
       "      <td>25.89</td>\n",
       "      <td>30.42</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HuberRegressor()</td>\n",
       "      <td>25.81</td>\n",
       "      <td>32.81</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>25.94</td>\n",
       "      <td>30.32</td>\n",
       "      <td>7.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PoissonRegressor()</td>\n",
       "      <td>27.03</td>\n",
       "      <td>36.49</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>27.48</td>\n",
       "      <td>30.98</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TweedieRegressor()</td>\n",
       "      <td>31.65</td>\n",
       "      <td>35.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.13</td>\n",
       "      <td>33.11</td>\n",
       "      <td>34.59</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GammaRegressor()</td>\n",
       "      <td>31.35</td>\n",
       "      <td>36.15</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.12</td>\n",
       "      <td>32.73</td>\n",
       "      <td>34.54</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PassiveAggressiveRegressor()</td>\n",
       "      <td>33.36</td>\n",
       "      <td>51.92</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.72</td>\n",
       "      <td>32.41</td>\n",
       "      <td>46.06</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RANSACRegressor()</td>\n",
       "      <td>34.78</td>\n",
       "      <td>44.25</td>\n",
       "      <td>4481317912233.71</td>\n",
       "      <td>43966068893931478116728832.00</td>\n",
       "      <td>216677161262368121946112.00</td>\n",
       "      <td>1835433935713905336647680.00</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVR()</td>\n",
       "      <td>26.14</td>\n",
       "      <td>32.62</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.14</td>\n",
       "      <td>26.28</td>\n",
       "      <td>30.35</td>\n",
       "      <td>53.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NuSVR()</td>\n",
       "      <td>21.14</td>\n",
       "      <td>26.34</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.11</td>\n",
       "      <td>24.30</td>\n",
       "      <td>28.27</td>\n",
       "      <td>245.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVR()</td>\n",
       "      <td>19.99</td>\n",
       "      <td>25.81</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.11</td>\n",
       "      <td>24.15</td>\n",
       "      <td>28.15</td>\n",
       "      <td>278.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>26.12</td>\n",
       "      <td>37.70</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExtraTreeRegressor()</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.17</td>\n",
       "      <td>27.15</td>\n",
       "      <td>37.87</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TheilSenRegressor(max_subpopulation=10000)</td>\n",
       "      <td>32.35</td>\n",
       "      <td>50.78</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.94</td>\n",
       "      <td>32.43</td>\n",
       "      <td>49.84</td>\n",
       "      <td>320.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>6.93</td>\n",
       "      <td>10.20</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>19.07</td>\n",
       "      <td>25.31</td>\n",
       "      <td>146.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(DecisionTreeRegressor(max_depth=3, random_sta...</td>\n",
       "      <td>28.18</td>\n",
       "      <td>35.65</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.15</td>\n",
       "      <td>29.16</td>\n",
       "      <td>35.14</td>\n",
       "      <td>29.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>21.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.13</td>\n",
       "      <td>21.90</td>\n",
       "      <td>26.75</td>\n",
       "      <td>45.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  Train MAPE  Train RMSE  \\\n",
       "0                                  LinearRegression()       25.61       32.64   \n",
       "1                                             Ridge()       25.59       32.65   \n",
       "2                                      SGDRegressor()       25.63       33.44   \n",
       "3                                        ElasticNet()       41.46       45.44   \n",
       "4                                              Lars()       25.78       32.62   \n",
       "5                                             Lasso()       46.31       50.42   \n",
       "6                                         LassoLars()       50.96       53.97   \n",
       "7                         OrthogonalMatchingPursuit()       30.14       36.05   \n",
       "8                                     ARDRegression()       25.62       32.69   \n",
       "9                                     BayesianRidge()       25.62       32.63   \n",
       "10                                   HuberRegressor()       25.81       32.81   \n",
       "11                                 PoissonRegressor()       27.03       36.49   \n",
       "12                                 TweedieRegressor()       31.65       35.62   \n",
       "13                                   GammaRegressor()       31.35       36.15   \n",
       "14                       PassiveAggressiveRegressor()       33.36       51.92   \n",
       "15                                  RANSACRegressor()       34.78       44.25   \n",
       "16                                        LinearSVR()       26.14       32.62   \n",
       "17                                            NuSVR()       21.14       26.34   \n",
       "18                                              SVR()       19.99       25.81   \n",
       "19                            DecisionTreeRegressor()        0.03        0.63   \n",
       "20                               ExtraTreeRegressor()        0.03        0.63   \n",
       "21         TheilSenRegressor(max_subpopulation=10000)       32.35       50.78   \n",
       "22  (DecisionTreeRegressor(max_features='auto', ra...        6.93       10.20   \n",
       "23  (DecisionTreeRegressor(max_depth=3, random_sta...       28.18       35.65   \n",
       "24  ([DecisionTreeRegressor(criterion='friedman_ms...       21.56       27.49   \n",
       "\n",
       "      Train CV Mean                  Train CV STD  \\\n",
       "0              1.49                          0.14   \n",
       "1              1.49                          0.14   \n",
       "2              1.51                          0.15   \n",
       "3              2.10                          0.18   \n",
       "4              1.49                          0.13   \n",
       "5              2.32                          0.22   \n",
       "6              2.50                          0.24   \n",
       "7              1.67                          0.17   \n",
       "8              1.49                          0.14   \n",
       "9              1.49                          0.13   \n",
       "10             1.49                          0.14   \n",
       "11             1.56                          0.44   \n",
       "12             1.67                          0.13   \n",
       "13             1.67                          0.12   \n",
       "14             2.29                          0.72   \n",
       "15 4481317912233.71 43966068893931478116728832.00   \n",
       "16             1.50                          0.14   \n",
       "17             1.39                          0.11   \n",
       "18             1.38                          0.11   \n",
       "19             1.75                          0.11   \n",
       "20             1.79                          0.17   \n",
       "21             3.36                          0.94   \n",
       "22             1.23                          0.10   \n",
       "23             1.61                          0.15   \n",
       "24             1.31                          0.13   \n",
       "\n",
       "                         Test MAPE                        Test RMSE  \\\n",
       "0  1552236677610843430243532800.00 13148722540706265264736436224.00   \n",
       "1                            25.86                            30.43   \n",
       "2                            25.65                            30.69   \n",
       "3                            43.95                            44.97   \n",
       "4                            26.09                            30.44   \n",
       "5                            49.03                            49.88   \n",
       "6                            54.35                            53.59   \n",
       "7                            30.95                            34.74   \n",
       "8                            25.90                            30.44   \n",
       "9                            25.89                            30.42   \n",
       "10                           25.94                            30.32   \n",
       "11                           27.48                            30.98   \n",
       "12                           33.11                            34.59   \n",
       "13                           32.73                            34.54   \n",
       "14                           32.41                            46.06   \n",
       "15     216677161262368121946112.00     1835433935713905336647680.00   \n",
       "16                           26.28                            30.35   \n",
       "17                           24.30                            28.27   \n",
       "18                           24.15                            28.15   \n",
       "19                           26.12                            37.70   \n",
       "20                           27.15                            37.87   \n",
       "21                           32.43                            49.84   \n",
       "22                           19.07                            25.31   \n",
       "23                           29.16                            35.14   \n",
       "24                           21.90                            26.75   \n",
       "\n",
       "    Time Taken  \n",
       "0         1.02  \n",
       "1         0.31  \n",
       "2         1.19  \n",
       "3         0.40  \n",
       "4         0.60  \n",
       "5         0.37  \n",
       "6         0.29  \n",
       "7         0.30  \n",
       "8         3.34  \n",
       "9         0.74  \n",
       "10        7.56  \n",
       "11        0.67  \n",
       "12        0.27  \n",
       "13        0.41  \n",
       "14        0.77  \n",
       "15        6.08  \n",
       "16       53.49  \n",
       "17      245.73  \n",
       "18      278.39  \n",
       "19        2.62  \n",
       "20        2.16  \n",
       "21      320.35  \n",
       "22      146.29  \n",
       "23       29.44  \n",
       "24       45.41  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>19.07</td>\n",
       "      <td>25.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>21.90</td>\n",
       "      <td>26.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVR()</td>\n",
       "      <td>24.15</td>\n",
       "      <td>28.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NuSVR()</td>\n",
       "      <td>24.30</td>\n",
       "      <td>28.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HuberRegressor()</td>\n",
       "      <td>25.94</td>\n",
       "      <td>30.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVR()</td>\n",
       "      <td>26.28</td>\n",
       "      <td>30.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BayesianRidge()</td>\n",
       "      <td>25.89</td>\n",
       "      <td>30.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge()</td>\n",
       "      <td>25.86</td>\n",
       "      <td>30.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lars()</td>\n",
       "      <td>26.09</td>\n",
       "      <td>30.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARDRegression()</td>\n",
       "      <td>25.90</td>\n",
       "      <td>30.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDRegressor()</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PoissonRegressor()</td>\n",
       "      <td>27.48</td>\n",
       "      <td>30.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GammaRegressor()</td>\n",
       "      <td>32.73</td>\n",
       "      <td>34.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TweedieRegressor()</td>\n",
       "      <td>33.11</td>\n",
       "      <td>34.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OrthogonalMatchingPursuit()</td>\n",
       "      <td>30.95</td>\n",
       "      <td>34.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(DecisionTreeRegressor(max_depth=3, random_sta...</td>\n",
       "      <td>29.16</td>\n",
       "      <td>35.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>26.12</td>\n",
       "      <td>37.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExtraTreeRegressor()</td>\n",
       "      <td>27.15</td>\n",
       "      <td>37.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>43.95</td>\n",
       "      <td>44.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PassiveAggressiveRegressor()</td>\n",
       "      <td>32.41</td>\n",
       "      <td>46.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TheilSenRegressor(max_subpopulation=10000)</td>\n",
       "      <td>32.43</td>\n",
       "      <td>49.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso()</td>\n",
       "      <td>49.03</td>\n",
       "      <td>49.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoLars()</td>\n",
       "      <td>54.35</td>\n",
       "      <td>53.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RANSACRegressor()</td>\n",
       "      <td>216677161262368121946112.00</td>\n",
       "      <td>1835433935713905336647680.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>1552236677610843430243532800.00</td>\n",
       "      <td>13148722540706265264736436224.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  \\\n",
       "22  (DecisionTreeRegressor(max_features='auto', ra...   \n",
       "24  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "18                                              SVR()   \n",
       "17                                            NuSVR()   \n",
       "10                                   HuberRegressor()   \n",
       "16                                        LinearSVR()   \n",
       "9                                     BayesianRidge()   \n",
       "1                                             Ridge()   \n",
       "4                                              Lars()   \n",
       "8                                     ARDRegression()   \n",
       "2                                      SGDRegressor()   \n",
       "11                                 PoissonRegressor()   \n",
       "13                                   GammaRegressor()   \n",
       "12                                 TweedieRegressor()   \n",
       "7                         OrthogonalMatchingPursuit()   \n",
       "23  (DecisionTreeRegressor(max_depth=3, random_sta...   \n",
       "19                            DecisionTreeRegressor()   \n",
       "20                               ExtraTreeRegressor()   \n",
       "3                                        ElasticNet()   \n",
       "14                       PassiveAggressiveRegressor()   \n",
       "21         TheilSenRegressor(max_subpopulation=10000)   \n",
       "5                                             Lasso()   \n",
       "6                                         LassoLars()   \n",
       "15                                  RANSACRegressor()   \n",
       "0                                  LinearRegression()   \n",
       "\n",
       "                         Test MAPE                        Test RMSE  \n",
       "22                           19.07                            25.31  \n",
       "24                           21.90                            26.75  \n",
       "18                           24.15                            28.15  \n",
       "17                           24.30                            28.27  \n",
       "10                           25.94                            30.32  \n",
       "16                           26.28                            30.35  \n",
       "9                            25.89                            30.42  \n",
       "1                            25.86                            30.43  \n",
       "4                            26.09                            30.44  \n",
       "8                            25.90                            30.44  \n",
       "2                            25.65                            30.69  \n",
       "11                           27.48                            30.98  \n",
       "13                           32.73                            34.54  \n",
       "12                           33.11                            34.59  \n",
       "7                            30.95                            34.74  \n",
       "23                           29.16                            35.14  \n",
       "19                           26.12                            37.70  \n",
       "20                           27.15                            37.87  \n",
       "3                            43.95                            44.97  \n",
       "14                           32.41                            46.06  \n",
       "21                           32.43                            49.84  \n",
       "5                            49.03                            49.88  \n",
       "6                            54.35                            53.59  \n",
       "15     216677161262368121946112.00     1835433935713905336647680.00  \n",
       "0  1552236677610843430243532800.00 13148722540706265264736436224.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models[['Model','Test MAPE','Test RMSE']].sort_values(by='Test RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_5_predictions(models,X_train,y_train,X_test,y_test):\n",
    "    plt.figure(figsize=(10,9))\n",
    "    plt_colours = ['gd','b^','ys','r*','+']\n",
    "    X_test_values = X_test[0:5]\n",
    "    y_test_values = y_test[0:5]\n",
    "    y_labels = [0,1,2,3,4]\n",
    "    for colour,model in enumerate(models):\n",
    "        current_model = model.fit(X_train,y_train)\n",
    "        predictions = current_model.predict(X_test_values)\n",
    "        plt.plot(predictions,plt_colours[colour],label=str(model))\n",
    "    \n",
    "    plt.plot(y_test_values,'or',label='Actual')\n",
    "    plt.xlabel('Test Sample')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_5_models = [RandomForestRegressor(),GradientBoostingRegressor(),SVR(),\n",
    "                NuSVR(),Ridge()]\n",
    "plot_first_5_predictions(top_5_models,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis after 1st linear Regression. There was 1 result in the X_test prediciton that was causing the error to sky rocket. This was because the category 'listingInfo.buyItNowAvailable' had 17992 values for false and then 1 value for True and it was majorly messing up the model. So I decided to remove this column and see how it affected the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_altered = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_altered = df_1_altered.drop(columns='listingInfo.buyItNowAvailable')\n",
    "##Removing the acutal value where'listingInfo.buyItNowAvailable'' actually equals 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = create_training_and_test_data(df_1_altered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14394, 81)\n",
      "(3599, 81)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing : LinearRegression() : This is model : 1 out of 25 \n",
      "Now doing : Ridge() : This is model : 2 out of 25 \n",
      "Now doing : SGDRegressor() : This is model : 3 out of 25 \n",
      "Now doing : ElasticNet() : This is model : 4 out of 25 \n",
      "Now doing : Lars() : This is model : 5 out of 25 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.313e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=6.540e-04, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=3.190e-04, with an active set of 43 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.594e-04, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=2.486e-04, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.215e-04, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.863e-05, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=4.208e-06, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=5.661e-04, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=9.795e-05, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=5.776e-05, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=2.046e-05, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.622e-05, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=5.832e-06, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=1.040e-06, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.339e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=6.511e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=4.262e-04, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=1.094e-04, with an active set of 63 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.029e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.018e-05, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=1.396e-05, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=6.273e-06, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.697e-07, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.421e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=7.732e-04, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=2.791e-04, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.345e-04, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=6.071e-05, with an active set of 73 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=5.622e-05, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.747e-05, with an active set of 75 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.100e-05, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=7.211e-06, with an active set of 77 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=1.274e-06, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.249e-07, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.409e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=7.348e-04, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.317e-04, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.300e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=1.951e-05, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=9.858e-06, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=7.382e-07, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.386e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.956e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=4.083e-04, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.669e-04, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=5.529e-05, with an active set of 74 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=4.276e-05, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=1.189e-05, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=4.225e-06, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.528e-06, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.022e-07, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.446e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=7.296e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=4.268e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.331e-04, with an active set of 61 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=7.613e-05, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.599e-05, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.733e-05, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.389e-06, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.506e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=6.912e-04, with an active set of 30 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=4.654e-04, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=2.194e-04, with an active set of 52 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.058e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.002e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.950e-05, with an active set of 72 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.109e-05, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=9.314e-06, with an active set of 78 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.844e-06, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.621e-06, with an active set of 79 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.351e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=6.613e-04, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=3.252e-04, with an active set of 42 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.133e-04, with an active set of 67 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.546e-03, with an active set of 16 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.976e-04, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.250e-04, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.171e-04, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.071e-04, with an active set of 64 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.309e-05, with an active set of 70 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=4.914e-05, with an active set of 71 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=8.978e-07, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing : Lasso() : This is model : 6 out of 25 \n",
      "Now doing : LassoLars() : This is model : 7 out of 25 \n",
      "Now doing : OrthogonalMatchingPursuit() : This is model : 8 out of 25 \n",
      "Now doing : ARDRegression() : This is model : 9 out of 25 \n",
      "Now doing : BayesianRidge() : This is model : 10 out of 25 \n",
      "Now doing : HuberRegressor() : This is model : 11 out of 25 \n",
      "Now doing : PoissonRegressor() : This is model : 12 out of 25 \n",
      "Now doing : TweedieRegressor() : This is model : 13 out of 25 \n",
      "Now doing : GammaRegressor() : This is model : 14 out of 25 \n",
      "Now doing : PassiveAggressiveRegressor() : This is model : 15 out of 25 \n",
      "Now doing : RANSACRegressor() : This is model : 16 out of 25 \n",
      "Now doing : LinearSVR() : This is model : 17 out of 25 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing : NuSVR() : This is model : 18 out of 25 \n",
      "Now doing : SVR() : This is model : 19 out of 25 \n",
      "Now doing : DecisionTreeRegressor() : This is model : 20 out of 25 \n",
      "Now doing : ExtraTreeRegressor() : This is model : 21 out of 25 \n",
      "Now doing : TheilSenRegressor(max_subpopulation=10000) : This is model : 22 out of 25 \n",
      "Now doing : RandomForestRegressor() : This is model : 23 out of 25 \n",
      "Now doing : AdaBoostRegressor() : This is model : 24 out of 25 \n",
      "Now doing : GradientBoostingRegressor() : This is model : 25 out of 25 \n",
      "Time taken : 1147.195858001709\n"
     ]
    }
   ],
   "source": [
    "df_1_altered_results = run_models(models,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MAPE</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Train CV Mean</th>\n",
       "      <th>Train CV STD</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>25.59</td>\n",
       "      <td>32.65</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>25.86</td>\n",
       "      <td>30.43</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge()</td>\n",
       "      <td>25.59</td>\n",
       "      <td>32.65</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>25.86</td>\n",
       "      <td>30.43</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDRegressor()</td>\n",
       "      <td>25.73</td>\n",
       "      <td>33.08</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.14</td>\n",
       "      <td>25.99</td>\n",
       "      <td>30.87</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>41.46</td>\n",
       "      <td>45.44</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>43.95</td>\n",
       "      <td>44.97</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lars()</td>\n",
       "      <td>25.73</td>\n",
       "      <td>32.63</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>26.04</td>\n",
       "      <td>30.43</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso()</td>\n",
       "      <td>46.31</td>\n",
       "      <td>50.42</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>49.03</td>\n",
       "      <td>49.88</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoLars()</td>\n",
       "      <td>50.96</td>\n",
       "      <td>53.97</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.24</td>\n",
       "      <td>54.35</td>\n",
       "      <td>53.59</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OrthogonalMatchingPursuit()</td>\n",
       "      <td>30.14</td>\n",
       "      <td>36.05</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.17</td>\n",
       "      <td>30.95</td>\n",
       "      <td>34.74</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARDRegression()</td>\n",
       "      <td>25.62</td>\n",
       "      <td>32.69</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>25.90</td>\n",
       "      <td>30.44</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BayesianRidge()</td>\n",
       "      <td>25.62</td>\n",
       "      <td>32.63</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.13</td>\n",
       "      <td>25.89</td>\n",
       "      <td>30.42</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HuberRegressor()</td>\n",
       "      <td>25.81</td>\n",
       "      <td>32.81</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>26.02</td>\n",
       "      <td>30.33</td>\n",
       "      <td>7.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PoissonRegressor()</td>\n",
       "      <td>27.03</td>\n",
       "      <td>36.49</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>27.48</td>\n",
       "      <td>30.98</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TweedieRegressor()</td>\n",
       "      <td>31.65</td>\n",
       "      <td>35.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.13</td>\n",
       "      <td>33.11</td>\n",
       "      <td>34.59</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GammaRegressor()</td>\n",
       "      <td>31.35</td>\n",
       "      <td>36.15</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.12</td>\n",
       "      <td>32.73</td>\n",
       "      <td>34.54</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PassiveAggressiveRegressor()</td>\n",
       "      <td>34.26</td>\n",
       "      <td>47.49</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.96</td>\n",
       "      <td>34.95</td>\n",
       "      <td>46.12</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RANSACRegressor()</td>\n",
       "      <td>13666879279403479194402816.00</td>\n",
       "      <td>112475207210065326325628928.00</td>\n",
       "      <td>6464683709425.93</td>\n",
       "      <td>58868919816822157920436224.00</td>\n",
       "      <td>19197015435783912862777344.00</td>\n",
       "      <td>127016244081470614748004352.00</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVR()</td>\n",
       "      <td>26.07</td>\n",
       "      <td>32.71</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.13</td>\n",
       "      <td>26.31</td>\n",
       "      <td>30.42</td>\n",
       "      <td>42.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NuSVR()</td>\n",
       "      <td>21.14</td>\n",
       "      <td>26.34</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.11</td>\n",
       "      <td>24.25</td>\n",
       "      <td>28.24</td>\n",
       "      <td>238.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVR()</td>\n",
       "      <td>19.99</td>\n",
       "      <td>25.81</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.11</td>\n",
       "      <td>24.09</td>\n",
       "      <td>28.12</td>\n",
       "      <td>275.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.15</td>\n",
       "      <td>26.06</td>\n",
       "      <td>37.57</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExtraTreeRegressor()</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>27.55</td>\n",
       "      <td>38.14</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TheilSenRegressor(max_subpopulation=10000)</td>\n",
       "      <td>32.45</td>\n",
       "      <td>51.04</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.99</td>\n",
       "      <td>32.21</td>\n",
       "      <td>50.00</td>\n",
       "      <td>303.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>6.96</td>\n",
       "      <td>10.30</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>19.14</td>\n",
       "      <td>25.40</td>\n",
       "      <td>164.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(DecisionTreeRegressor(max_depth=3, random_sta...</td>\n",
       "      <td>28.35</td>\n",
       "      <td>35.70</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.15</td>\n",
       "      <td>29.30</td>\n",
       "      <td>35.20</td>\n",
       "      <td>36.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>21.56</td>\n",
       "      <td>27.49</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.13</td>\n",
       "      <td>21.89</td>\n",
       "      <td>26.75</td>\n",
       "      <td>58.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  \\\n",
       "0                                  LinearRegression()   \n",
       "1                                             Ridge()   \n",
       "2                                      SGDRegressor()   \n",
       "3                                        ElasticNet()   \n",
       "4                                              Lars()   \n",
       "5                                             Lasso()   \n",
       "6                                         LassoLars()   \n",
       "7                         OrthogonalMatchingPursuit()   \n",
       "8                                     ARDRegression()   \n",
       "9                                     BayesianRidge()   \n",
       "10                                   HuberRegressor()   \n",
       "11                                 PoissonRegressor()   \n",
       "12                                 TweedieRegressor()   \n",
       "13                                   GammaRegressor()   \n",
       "14                       PassiveAggressiveRegressor()   \n",
       "15                                  RANSACRegressor()   \n",
       "16                                        LinearSVR()   \n",
       "17                                            NuSVR()   \n",
       "18                                              SVR()   \n",
       "19                            DecisionTreeRegressor()   \n",
       "20                               ExtraTreeRegressor()   \n",
       "21         TheilSenRegressor(max_subpopulation=10000)   \n",
       "22  (DecisionTreeRegressor(max_features='auto', ra...   \n",
       "23  (DecisionTreeRegressor(max_depth=3, random_sta...   \n",
       "24  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "\n",
       "                      Train MAPE                     Train RMSE  \\\n",
       "0                          25.59                          32.65   \n",
       "1                          25.59                          32.65   \n",
       "2                          25.73                          33.08   \n",
       "3                          41.46                          45.44   \n",
       "4                          25.73                          32.63   \n",
       "5                          46.31                          50.42   \n",
       "6                          50.96                          53.97   \n",
       "7                          30.14                          36.05   \n",
       "8                          25.62                          32.69   \n",
       "9                          25.62                          32.63   \n",
       "10                         25.81                          32.81   \n",
       "11                         27.03                          36.49   \n",
       "12                         31.65                          35.62   \n",
       "13                         31.35                          36.15   \n",
       "14                         34.26                          47.49   \n",
       "15 13666879279403479194402816.00 112475207210065326325628928.00   \n",
       "16                         26.07                          32.71   \n",
       "17                         21.14                          26.34   \n",
       "18                         19.99                          25.81   \n",
       "19                          0.03                           0.63   \n",
       "20                          0.03                           0.63   \n",
       "21                         32.45                          51.04   \n",
       "22                          6.96                          10.30   \n",
       "23                         28.35                          35.70   \n",
       "24                         21.56                          27.49   \n",
       "\n",
       "      Train CV Mean                  Train CV STD  \\\n",
       "0              1.49                          0.14   \n",
       "1              1.49                          0.14   \n",
       "2              1.50                          0.14   \n",
       "3              2.10                          0.18   \n",
       "4              1.49                          0.14   \n",
       "5              2.32                          0.22   \n",
       "6              2.50                          0.24   \n",
       "7              1.67                          0.17   \n",
       "8              1.49                          0.14   \n",
       "9              1.49                          0.13   \n",
       "10             1.49                          0.14   \n",
       "11             1.56                          0.44   \n",
       "12             1.67                          0.13   \n",
       "13             1.67                          0.12   \n",
       "14             2.29                          0.96   \n",
       "15 6464683709425.93 58868919816822157920436224.00   \n",
       "16             1.50                          0.13   \n",
       "17             1.39                          0.11   \n",
       "18             1.38                          0.11   \n",
       "19             1.76                          0.15   \n",
       "20             1.80                          0.20   \n",
       "21             3.39                          0.99   \n",
       "22             1.24                          0.10   \n",
       "23             1.61                          0.15   \n",
       "24             1.31                          0.13   \n",
       "\n",
       "                       Test MAPE                      Test RMSE  Time Taken  \n",
       "0                          25.86                          30.43        0.52  \n",
       "1                          25.86                          30.43        0.22  \n",
       "2                          25.99                          30.87        1.01  \n",
       "3                          43.95                          44.97        0.39  \n",
       "4                          26.04                          30.43        0.52  \n",
       "5                          49.03                          49.88        0.33  \n",
       "6                          54.35                          53.59        0.28  \n",
       "7                          30.95                          34.74        0.32  \n",
       "8                          25.90                          30.44        2.94  \n",
       "9                          25.89                          30.42        0.82  \n",
       "10                         26.02                          30.33        7.74  \n",
       "11                         27.48                          30.98        0.80  \n",
       "12                         33.11                          34.59        0.31  \n",
       "13                         32.73                          34.54        0.45  \n",
       "14                         34.95                          46.12        0.85  \n",
       "15 19197015435783912862777344.00 127016244081470614748004352.00        5.26  \n",
       "16                         26.31                          30.42       42.91  \n",
       "17                         24.25                          28.24      238.30  \n",
       "18                         24.09                          28.12      275.83  \n",
       "19                         26.06                          37.57        2.80  \n",
       "20                         27.55                          38.14        2.04  \n",
       "21                         32.21                          50.00      303.62  \n",
       "22                         19.14                          25.40      164.26  \n",
       "23                         29.30                          35.20       36.08  \n",
       "24                         21.89                          26.75       58.51  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "df_1_altered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test MAPE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "      <td>19.14</td>\n",
       "      <td>25.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>21.89</td>\n",
       "      <td>26.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVR()</td>\n",
       "      <td>24.09</td>\n",
       "      <td>28.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NuSVR()</td>\n",
       "      <td>24.25</td>\n",
       "      <td>28.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HuberRegressor()</td>\n",
       "      <td>26.02</td>\n",
       "      <td>30.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BayesianRidge()</td>\n",
       "      <td>25.89</td>\n",
       "      <td>30.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVR()</td>\n",
       "      <td>26.31</td>\n",
       "      <td>30.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>25.86</td>\n",
       "      <td>30.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge()</td>\n",
       "      <td>25.86</td>\n",
       "      <td>30.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lars()</td>\n",
       "      <td>26.04</td>\n",
       "      <td>30.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARDRegression()</td>\n",
       "      <td>25.90</td>\n",
       "      <td>30.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDRegressor()</td>\n",
       "      <td>25.99</td>\n",
       "      <td>30.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PoissonRegressor()</td>\n",
       "      <td>27.48</td>\n",
       "      <td>30.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GammaRegressor()</td>\n",
       "      <td>32.73</td>\n",
       "      <td>34.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TweedieRegressor()</td>\n",
       "      <td>33.11</td>\n",
       "      <td>34.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OrthogonalMatchingPursuit()</td>\n",
       "      <td>30.95</td>\n",
       "      <td>34.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(DecisionTreeRegressor(max_depth=3, random_sta...</td>\n",
       "      <td>29.30</td>\n",
       "      <td>35.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>26.06</td>\n",
       "      <td>37.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExtraTreeRegressor()</td>\n",
       "      <td>27.55</td>\n",
       "      <td>38.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet()</td>\n",
       "      <td>43.95</td>\n",
       "      <td>44.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PassiveAggressiveRegressor()</td>\n",
       "      <td>34.95</td>\n",
       "      <td>46.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso()</td>\n",
       "      <td>49.03</td>\n",
       "      <td>49.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TheilSenRegressor(max_subpopulation=10000)</td>\n",
       "      <td>32.21</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoLars()</td>\n",
       "      <td>54.35</td>\n",
       "      <td>53.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RANSACRegressor()</td>\n",
       "      <td>19197015435783912862777344.00</td>\n",
       "      <td>127016244081470614748004352.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  \\\n",
       "22  (DecisionTreeRegressor(max_features='auto', ra...   \n",
       "24  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "18                                              SVR()   \n",
       "17                                            NuSVR()   \n",
       "10                                   HuberRegressor()   \n",
       "9                                     BayesianRidge()   \n",
       "16                                        LinearSVR()   \n",
       "0                                  LinearRegression()   \n",
       "1                                             Ridge()   \n",
       "4                                              Lars()   \n",
       "8                                     ARDRegression()   \n",
       "2                                      SGDRegressor()   \n",
       "11                                 PoissonRegressor()   \n",
       "13                                   GammaRegressor()   \n",
       "12                                 TweedieRegressor()   \n",
       "7                         OrthogonalMatchingPursuit()   \n",
       "23  (DecisionTreeRegressor(max_depth=3, random_sta...   \n",
       "19                            DecisionTreeRegressor()   \n",
       "20                               ExtraTreeRegressor()   \n",
       "3                                        ElasticNet()   \n",
       "14                       PassiveAggressiveRegressor()   \n",
       "5                                             Lasso()   \n",
       "21         TheilSenRegressor(max_subpopulation=10000)   \n",
       "6                                         LassoLars()   \n",
       "15                                  RANSACRegressor()   \n",
       "\n",
       "                       Test MAPE                      Test RMSE  \n",
       "22                         19.14                          25.40  \n",
       "24                         21.89                          26.75  \n",
       "18                         24.09                          28.12  \n",
       "17                         24.25                          28.24  \n",
       "10                         26.02                          30.33  \n",
       "9                          25.89                          30.42  \n",
       "16                         26.31                          30.42  \n",
       "0                          25.86                          30.43  \n",
       "1                          25.86                          30.43  \n",
       "4                          26.04                          30.43  \n",
       "8                          25.90                          30.44  \n",
       "2                          25.99                          30.87  \n",
       "11                         27.48                          30.98  \n",
       "13                         32.73                          34.54  \n",
       "12                         33.11                          34.59  \n",
       "7                          30.95                          34.74  \n",
       "23                         29.30                          35.20  \n",
       "19                         26.06                          37.57  \n",
       "20                         27.55                          38.14  \n",
       "3                          43.95                          44.97  \n",
       "14                         34.95                          46.12  \n",
       "5                          49.03                          49.88  \n",
       "21                         32.21                          50.00  \n",
       "6                          54.35                          53.59  \n",
       "15 19197015435783912862777344.00 127016244081470614748004352.00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_altered_results[['Model','Test MAPE','Test RMSE']].sort_values(by='Test RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like RandomForestRegressor() did the best then GradientBoostingRegressor(), SVR(), NuSVR() and then a lot of the models have the same RMSE. I'll try and random grid search some of the best models to try and improve the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
